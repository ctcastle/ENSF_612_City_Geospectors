{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41d2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libaries \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import wget \n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373a169",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94d3d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                       int64\n",
      "Month                      int64\n",
      "Day                        int64\n",
      "Cloudiness                object\n",
      "Greenness                 object\n",
      "Estimated Usability       object\n",
      "Area Estimate              int64\n",
      "Top Right Latitude       float64\n",
      "Top Right Longitude      float64\n",
      "Bottom Left Latitude     float64\n",
      "Bottom Left Longitude    float64\n",
      "Image Filename            object\n",
      "URL                       object\n",
      "dtype: object\n",
      "    Year  Month  Day Cloudiness    Greenness Estimated Usability  \\\n",
      "0   2024      7    8       None         High                High   \n",
      "1   2023      7   23       None         High                High   \n",
      "2   2022      7   24       None         High                High   \n",
      "3   2021      7    1       None  Medium-High         Medium-High   \n",
      "4   2020      7   27       None         High                High   \n",
      "5   2019      7   23       None         High                High   \n",
      "6   2018      7   16       None         High                High   \n",
      "7   2017      7    5       None         High                High   \n",
      "8   2016      7   29       None         High                High   \n",
      "9   2015      7    9       None         High                High   \n",
      "10  2014      7   27       None         High                High   \n",
      "11  2013      7    2      Light         High                High   \n",
      "12  2012      8    4       None         High                High   \n",
      "13  2011      7   17       None         High                High   \n",
      "14  2010      7    9       None         High                High   \n",
      "15  2009      7   25       None         High                High   \n",
      "16  2008      7   20       None         High                High   \n",
      "17  2007      7   20       None         High                High   \n",
      "18  2006      7   16       None         High                High   \n",
      "19  2005      7    8       None         High                High   \n",
      "20  2004      7   17       None         High                High   \n",
      "21  2003      7   17       None         High                High   \n",
      "22  2002      7   10       None  Medium-High         Medium-High   \n",
      "23  2001      7    4       None         High                High   \n",
      "\n",
      "    Area Estimate  Top Right Latitude  Top Right Longitude  \\\n",
      "0             854             51.3769            -113.7319   \n",
      "1             864             51.3769            -113.7319   \n",
      "2             830             51.3769            -113.7319   \n",
      "3             836             51.3769            -113.7319   \n",
      "4             804             51.3769            -113.7319   \n",
      "5             797             51.3769            -113.7319   \n",
      "6             786             51.3769            -113.7319   \n",
      "7             802             51.3769            -113.7319   \n",
      "8             768             51.3769            -113.7319   \n",
      "9             779             51.3769            -113.7319   \n",
      "10            771             51.3769            -113.7319   \n",
      "11            744             51.3769            -113.7319   \n",
      "12            742             51.3769            -113.7319   \n",
      "13            752             51.3769            -113.7319   \n",
      "14            744             51.3769            -113.7319   \n",
      "15            712             51.3769            -113.7319   \n",
      "16            702             51.3769            -113.7319   \n",
      "17            675             51.3769            -113.7319   \n",
      "18            682             51.3769            -113.7319   \n",
      "19            659             51.3769            -113.7319   \n",
      "20            623             51.3769            -113.7319   \n",
      "21            621             51.3769            -113.7319   \n",
      "22            591             51.3769            -113.7319   \n",
      "23            585             51.3769            -113.7319   \n",
      "\n",
      "    Bottom Left Latitude  Bottom Left Longitude Image Filename  \\\n",
      "0                50.7726              -114.3362   20240708.jpg   \n",
      "1                50.7726              -114.3362   20230723.jpg   \n",
      "2                50.7726              -114.3362   20220724.jpg   \n",
      "3                50.7726              -114.3362   20210701.jpg   \n",
      "4                50.7726              -114.3362   20200727.jpg   \n",
      "5                50.7726              -114.3362   20190723.jpg   \n",
      "6                50.7726              -114.3362   20180716.jpg   \n",
      "7                50.7726              -114.3362   20170705.jpg   \n",
      "8                50.7726              -114.3362   20160729.jpg   \n",
      "9                50.7726              -114.3362   20150709.jpg   \n",
      "10               50.7726              -114.3362   20140727.jpg   \n",
      "11               50.7726              -114.3362   20130702.jpg   \n",
      "12               50.7726              -114.3362   20120804.jpg   \n",
      "13               50.7726              -114.3362   20110717.jpg   \n",
      "14               50.7726              -114.3362   20100709.jpg   \n",
      "15               50.7726              -114.3362   20090725.jpg   \n",
      "16               50.7726              -114.3362   20080720.jpg   \n",
      "17               50.7726              -114.3362   20070720.jpg   \n",
      "18               50.7726              -114.3362   20060716.jpg   \n",
      "19               50.7726              -114.3362   20050708.jpg   \n",
      "20               50.7726              -114.3362   20040717.jpg   \n",
      "21               50.7726              -114.3362   20030717.jpg   \n",
      "22               50.7726              -114.3362   20020710.jpg   \n",
      "23               50.7726              -114.3362   20010704.jpg   \n",
      "\n",
      "                                                  URL  \n",
      "0   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "1   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "2   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "3   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "4   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "5   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "6   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "7   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "8   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "9   https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "10  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "11  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "12  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "13  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "14  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "15  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "16  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "17  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "18  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "19  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "20  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "21  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "22  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n",
      "23  https://wvs.earthdata.nasa.gov/api/v1/snapshot...  \n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from CSV \n",
    "\n",
    "imagery_df = pd.read_csv('basic_good_image_set.csv')\n",
    "imagery_df = imagery_df.fillna('None')\n",
    "print(imagery_df.dtypes)\n",
    "print(imagery_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5242ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n",
      "Image already in image folder\n"
     ]
    }
   ],
   "source": [
    "# Download files, should ONLY download if they are not already in to directory \n",
    "# Source of directory read technique: https://www.geeksforgeeks.org/python/python-list-files-in-a-directory/\n",
    "# If we need to do any os related things you can grab os from: https://www.google.com/search?q=get+os+version+python&sca_esv=7a3339a54e4f1566&ei=Y0EWaevMCJaA0PEPhtjtmQw&ved=0ahUKEwiriuy5_e-QAxUWADQIHQZsO8MQ4dUDCBE&uact=5&oq=get+os+version+python&gs_lp=Egxnd3Mtd2l6LXNlcnAiFWdldCBvcyB2ZXJzaW9uIHB5dGhvbjIFEAAYgAQyBhAAGBYYHjIGEAAYFhgeMggQABiABBiiBDIFEAAY7wUyBRAAGO8FSLZXUMYPWKBWcAN4AZABAJgBjAGgAcYOqgEEMTkuMrgBA8gBAPgBAZgCGKACtA_CAgoQABiwAxjWBBhHwgILEAAYgAQYkQIYigXCAhAQABiABBixAxhDGIMBGIoFwgIWEC4YgAQYsQMY0QMYQxiDARjHARiKBcICEBAuGIAEGNEDGEMYxwEYigXCAgoQABiABBhDGIoFwgIKEC4YgAQYQxiKBcICCxAuGIAEGMcBGK8BwgIOEC4YgAQYsQMYgwEY1ALCAg4QABiABBixAxiDARiKBcICBRAuGIAEwgIIEC4YgAQYsQPCAgQQABgDwgIOEC4YgAQYsQMY0QMYxwHCAg0QABiABBixAxhDGIoFwgINEC4YgAQYsQMYQxiKBcICCxAuGIAEGLEDGNQCwgILEAAYgAQYsQMYgwHCAggQABiABBixA8ICCxAuGIAEGLEDGIMBwgIcEC4YgAQYsQMYQxiKBRiXBRjcBBjeBBjgBNgBAcICCxAAGIAEGIYDGIoFmAMAiAYBkAYIugYGCAEQARgUkgcEMTguNqAH6aABsgcEMTUuNrgHqQ_CBwcwLjExLjEzyAdS&sclient=gws-wiz-serp\n",
    "\n",
    "# Select the path you want to evaluate, the only dataset currently is the basic known good image set \n",
    "path = './city_images/raw/basic_good_image_set' \n",
    "\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(len(imagery_df)):\n",
    "    image_fn = imagery_df['Image Filename'][i]\n",
    "    if not image_fn in dir_list:\n",
    "        print('Image not already in folder, downloading...')\n",
    "        image = wget.download(imagery_df['URL'][i],path+image_fn)\n",
    "    else:\n",
    "        print('Image already in image folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7aa30d",
   "metadata": {},
   "source": [
    "# Image Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c292c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of precleaned dataset: 24\n",
      "Total length of cleaned dataset: 22\n"
     ]
    }
   ],
   "source": [
    "# Only select images that do not have clouds and are in summer months, this will be more complicated if we don't manually label the cloudy data \n",
    "print(f'Total length of precleaned dataset: {len(imagery_df)}') \n",
    "cleaned_df = imagery_df.query(\"Month == 7 & Cloudiness.eq('None')\")\n",
    "print(f'Total length of cleaned dataset: {len(cleaned_df)}')\n",
    "\n",
    "for im_fn in cleaned_df['Image Filename']:\n",
    "    image = cv2.imread('./city_images/raw/basic_good_image_set/'+im_fn)\n",
    "    cv2.imwrite('./city_images/cleaned/basic_good_image_set/'+im_fn,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820b433",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713a8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose green thresholding values \n",
    "lower_green = np.array([37, 40, 40]) # Hue, Saturation, Value\n",
    "upper_green = np.array([85, 255, 255]) \n",
    "\n",
    "# Choose greyscale thresholding values \n",
    "lower_grey = 70  \n",
    "upper_grey = 255\n",
    "\n",
    "# Setup image list \n",
    "images_processed = [] \n",
    "# Setup loop for processing images \n",
    "for im_fn in cleaned_df['Image Filename']:\n",
    "    image = cv2.imread('./city_images/cleaned/basic_good_image_set/'+im_fn)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    image_mask = cv2.inRange(image, lower_green, upper_green)\n",
    "    image_inverted_mask = cv2.bitwise_not(image_mask)\n",
    "    image = cv2.bitwise_and(image, image, mask=image_inverted_mask)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, image_bitmask = cv2.threshold(image, lower_grey, upper_grey, cv2.THRESH_BINARY)\n",
    "    cv2.imwrite('./city_images/processed/basic_good_image_set/'+im_fn.split('.')[0]+'.bmp',image_bitmask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8e3ef",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535cc603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[457.01220495867767, 591.8981553719008, 792.831709090909, 1121.5441190082645, 664.4202842975207, 548.6230214876033, 997.2629950413223, 1005.8212760330579, 567.2651900826446, 661.2946512396694, 929.6525752066116, 451.9516561983471, 873.6144396694215, 324.6937388429752, 390.5180826446281, 564.1395570247934, 644.9967074380165, 542.1112859504133, 611.321732231405, 628.4010842975207, 1236.4855537190083, 419.50460826446283]\n"
     ]
    }
   ],
   "source": [
    "# Determine distances of image manually \n",
    "distance_width = 42 # km - determined from calculator: https://www.nhc.noaa.gov/gccalc.shtml\n",
    "distance_height = 67 # km - determined from calculator: \" \n",
    "\n",
    "area_per_year = [] \n",
    "\n",
    "for im_fn in cleaned_df['Image Filename']:\n",
    "    image = cv2.imread('./city_images/processed/basic_good_image_set/'+im_fn.split('.')[0]+'.bmp',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Calculate sq km per pixel \n",
    "    pixel_width = 275 \n",
    "    pixel_height = 275\n",
    "    sqkmpp = (distance_width*distance_height)/(pixel_height*pixel_width)\n",
    "\n",
    "    # Calculate area estimate \n",
    "    area_estimate = cv2.countNonZero(image)*sqkmpp\n",
    "    area_per_year.append(area_estimate)\n",
    "\n",
    "print(area_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36794cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(area_per_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = cleaned_df['Year']\n",
    "manual_area = cleaned_df['Area Estimate']\n",
    "print(years)\n",
    "print(manual_area)\n",
    "print(area_per_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8398b6f",
   "metadata": {},
   "source": [
    "# Graph Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "City Geospectors Environment",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
