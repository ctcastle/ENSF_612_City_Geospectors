{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b37784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_prefix: abfs://raw@ucalgarydatalake01.dfs.core.windows.net\n",
      "curated_prefix: abfs://curated@ucalgarydatalake01.dfs.core.windows.net\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Reads the .env file in the current directory\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from netCDF4 import Dataset\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, DateType\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "import os\n",
    "\n",
    "ACCOUNT_NAME = os.environ.get(\"ACCOUNT_NAME\")\n",
    "ACCOUNT_KEY = os.environ.get(\"ACCOUNT_KEY\")\n",
    "LAADS_TOKEN = os.environ.get(\"LAADS_TOKEN\")\n",
    "\n",
    "missing = [name for name, val in [\n",
    "    ('LAADS_TOKEN', LAADS_TOKEN),\n",
    "    ('ACCOUNT_NAME', ACCOUNT_NAME),\n",
    "    ('ACCOUNT_KEY', ACCOUNT_KEY),\n",
    "] if not val]\n",
    "if missing:\n",
    "    raise ValueError(f'Missing required environment variables: {missing}')\n",
    "PRODUCT = 'MCD06COSP_D3_MODIS'\n",
    "BASE_DETAILS_URL = 'https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/details'\n",
    "BASE_ARCHIVES_URL = 'https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives'\n",
    "headers_nasa = {\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'Authorization': f'Bearer {LAADS_TOKEN}',\n",
    "}\n",
    "LAT_N = 51.3769\n",
    "LAT_S = 50.7726\n",
    "LON_W = -114.3362\n",
    "LON_E = -113.7319\n",
    "RAW_CONTAINER = \"raw\"\n",
    "CURATED_CONTAINER = \"curated\"\n",
    "GOLD_CONTAINER = \"gold\"\n",
    "\n",
    "\n",
    "raw_prefix = f\"abfs://{RAW_CONTAINER}@{ACCOUNT_NAME}.dfs.core.windows.net\"\n",
    "curated_prefix = f\"abfs://{CURATED_CONTAINER}@{ACCOUNT_NAME}.dfs.core.windows.net\"\n",
    "\n",
    "storage_options = {\n",
    "    \"account_name\": ACCOUNT_NAME,\n",
    "    \"account_key\": ACCOUNT_KEY,\n",
    "}\n",
    "\n",
    "print(\"raw_prefix:\", raw_prefix)\n",
    "print(\"curated_prefix:\", curated_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6fd2fa-9d8a-4f85-ade0-e140d47fa986",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_CONTAINER = \"raw\"\n",
    "raw_prefix = f\"abfs://{RAW_CONTAINER}@{ACCOUNT_NAME}.dfs.core.windows.net\"\n",
    "storage_options = {\n",
    "    \"account_name\": ACCOUNT_NAME,\n",
    "    \"account_key\": ACCOUNT_KEY,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e1ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_mcd06cosp_filename(fname: str) -> datetime:\n",
    "    m = re.search(r'\\.A(\\d{4})(\\d{3})', fname)\n",
    "    if not m:\n",
    "        raise ValueError(f'Could not parse date from {fname}')\n",
    "    year = int(m.group(1))\n",
    "    doy = int(m.group(2))\n",
    "    return datetime.strptime(f'{year}{doy:03d}', '%Y%j')\n",
    "\n",
    "def compute_cloud_fraction_from_bytes(\n",
    "    file_bytes: bytes,\n",
    "    lat_s: float = LAT_S,\n",
    "    lat_n: float = LAT_N,\n",
    "    lon_w: float = LON_W,\n",
    "    lon_e: float = LON_E,\n",
    "    group_name: str = 'Cloud_Mask_Fraction',\n",
    ") -> float:\n",
    "    with Dataset('inmem', mode='r', memory=file_bytes) as nc:\n",
    "        lats = nc.variables['latitude'][:].astype(float)\n",
    "        lons = nc.variables['longitude'][:].astype(float)\n",
    "        nlat = lats.size\n",
    "        nlon = lons.size\n",
    "        if group_name not in nc.groups:\n",
    "            raise KeyError(f\"Group '{group_name}' not in {list(nc.groups.keys())}\")\n",
    "        grp = nc.groups[group_name]\n",
    "        if 'Mean' not in grp.variables:\n",
    "            raise KeyError(f\"'Mean' not found in group '{group_name}': {list(grp.variables.keys())}\")\n",
    "        cloud = grp.variables['Mean'][:].astype(float)\n",
    "        shape = cloud.shape\n",
    "        if shape == (nlat, nlon):\n",
    "            lat_first = True\n",
    "        elif shape == (nlon, nlat):\n",
    "            lat_first = False\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected cloud array shape {shape} with nlat={nlat}, nlon={nlon}')\n",
    "        lat_center = 0.5 * (lat_s + lat_n)\n",
    "        lon_center = 0.5 * (lon_w + lon_e)\n",
    "        lat_idx0 = int(np.argmin(np.abs(lats - lat_center)))\n",
    "        lon_idx0 = int(np.argmin(np.abs(lons - lon_center)))\n",
    "        lat_idx = np.arange(max(0, lat_idx0 - 1), min(nlat, lat_idx0 + 2))\n",
    "        lon_idx = np.arange(max(0, lon_idx0 - 1), min(nlon, lon_idx0 + 2))\n",
    "        if lat_idx.size == 0 or lon_idx.size == 0:\n",
    "            return float('nan')\n",
    "        if lat_first:\n",
    "            subset = cloud[np.ix_(lat_idx, lon_idx)]\n",
    "        else:\n",
    "            subset = cloud[np.ix_(lon_idx, lat_idx)]\n",
    "        subset = np.where(subset < -1e5, np.nan, subset)\n",
    "        if np.all(np.isnan(subset)):\n",
    "            return float('nan')\n",
    "        return float(np.nanmean(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32773fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "BASE_DETAILS_URL = \"https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/details\"\n",
    "\n",
    "def fetch_summer_details_for_year(year: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    lat_box = f\"[BBOX]N{LAT_N} S{LAT_S} W{LON_W} E{LON_E}\"\n",
    "\n",
    "    def extract_path(item: dict) -> str:\n",
    "        if \"downloadsLink\" in item:\n",
    "            url = item[\"downloadsLink\"]\n",
    "            return url.split(\"/archives/\", 1)[1]\n",
    "        if \"self\" in item:\n",
    "            url = item[\"self\"]\n",
    "            return url.split(\"/details/\", 1)[1]\n",
    "        if \"name\" in item:\n",
    "            return item[\"name\"]\n",
    "        raise KeyError(f\"No archive/path field in {list(item.keys())}\")\n",
    "\n",
    "    d = date(year, 6, 1)\n",
    "    end = date(year, 8, 31)\n",
    "\n",
    "    while d <= end:\n",
    "        temporal_range = f\"{d:%Y-%m-%d}..{d:%Y-%m-%d}\"\n",
    "        params = {\n",
    "            \"products\": PRODUCT,\n",
    "            \"temporalRanges\": temporal_range,\n",
    "            \"regions\": lat_box,\n",
    "            \"formats\": \"json\",\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            resp = requests.get(\n",
    "                BASE_DETAILS_URL,\n",
    "                params=params,\n",
    "                headers=headers_nasa,\n",
    "                timeout=60,\n",
    "            )\n",
    "            if resp.status_code >= 500:\n",
    "                print(f\"Year {year}, date {d}: LAADS {resp.status_code}, skipping\")\n",
    "                d += timedelta(days=1)\n",
    "                continue\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Year {year}, date {d}: request failed ({e}), skipping\")\n",
    "            d += timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        if isinstance(data, dict) and \"content\" in data:\n",
    "            items = data[\"content\"]\n",
    "        elif isinstance(data, list):\n",
    "            items = data\n",
    "        else:\n",
    "            items = []\n",
    "\n",
    "        for it in items:\n",
    "            rel_path = extract_path(it)\n",
    "            fname = it.get(\"name\", rel_path.split(\"/\")[-1])\n",
    "\n",
    "            if \"dataDay\" in it:\n",
    "                left = it[\"dataDay\"].split(\"=\", 1)[0].strip()\n",
    "                year_str, doy_str = left.split(\"-\")\n",
    "                dd = datetime.strptime(year_str + doy_str.zfill(3), \"%Y%j\").date()\n",
    "            else:\n",
    "                dd = date_from_mcd06cosp_filename(fname).date()\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"year\": dd.year,\n",
    "                    \"date\": dd,\n",
    "                    \"rel_path\": rel_path,\n",
    "                    \"file_name\": fname,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        d += timedelta(days=1)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"year\", \"date\", \"rel_path\", \"file_name\"])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4224a8eb-4a7e-48e3-96cb-ca6106ef68ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2005.parquet with 92 rows\n",
      "Year 2000: no data\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2004.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2002.parquet with 59 rows\n",
      "Year 2001: no data\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2003.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2007.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2008.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2006.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2009.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2010.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2011.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2012.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2015.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2014.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2013.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2016.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2017.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2018.parquet with 94 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2019.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2021.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2020.parquet with 88 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2022.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2023.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2024.parquet with 92 rows\n",
      "Wrote RAW abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_summer_2025.parquet with 92 rows\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "\n",
    "def process_year(year: int):\n",
    "    df_raw_year = fetch_summer_details_for_year(year)\n",
    "    if df_raw_year.empty:\n",
    "        print(f\"Year {year}: no data\")\n",
    "        return None\n",
    "    raw_path_year = f\"{raw_prefix}/laads_links_summer_{year}.parquet\"\n",
    "    df_raw_year.to_parquet(raw_path_year, index=False, storage_options=storage_options)\n",
    "    print(f\"Wrote RAW {raw_path_year} with {len(df_raw_year)} rows\")\n",
    "    return raw_path_year\n",
    "\n",
    "years = list(range(2000, 2026))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=6) as ex:\n",
    "    futures = {ex.submit(process_year, y): y for y in years}\n",
    "    for fut in as_completed(futures):\n",
    "        p = fut.result()\n",
    "        if p is not None:\n",
    "            paths.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fa7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote manifest to: abfs://raw@ucalgarydatalake01.dfs.core.windows.net/laads_links_manifest.parquet\n"
     ]
    }
   ],
   "source": [
    "paths_df = pd.DataFrame({'raw_path': paths})\n",
    "manifest_path = f'{raw_prefix}/laads_links_manifest.parquet'\n",
    "paths_df.to_parquet(manifest_path, index=False, storage_options=storage_options)\n",
    "print('Wrote manifest to:', manifest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89566124-7dca-456d-939e-a9010ee63303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw rows: 2173\n",
      "Wrote CURATED to: abfs://curated@ucalgarydatalake01.dfs.core.windows.net/calgary_cloud_fraction_summers_2000_2025.parquet\n"
     ]
    }
   ],
   "source": [
    "manifest_path = f'{raw_prefix}/laads_links_manifest.parquet'\n",
    "paths_df = pd.read_parquet(manifest_path, storage_options=storage_options)\n",
    "paths = paths_df['raw_path'].tolist()\n",
    "\n",
    "dfs = [\n",
    "    pd.read_parquet(p, storage_options=storage_options)\n",
    "    for p in paths\n",
    "]\n",
    "\n",
    "df_raw_pd = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Total raw rows:\", len(df_raw_pd))\n",
    "\n",
    "\n",
    "def fetch_cf_for_rel_path(rel_path: str) -> float:\n",
    "    try:\n",
    "        url = f\"{BASE_ARCHIVES_URL}/{rel_path.lstrip('/')}\"\n",
    "        r = requests.get(url, headers=headers_nasa, stream=True, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        return compute_cloud_fraction_from_bytes(r.content)\n",
    "    except Exception as e:\n",
    "        print(\"failed for\", rel_path, \"->\", e)\n",
    "        return float(\"nan\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=16) as pool:\n",
    "    cf_values = list(pool.map(fetch_cf_for_rel_path, df_raw_pd[\"rel_path\"].tolist()))\n",
    "\n",
    "df_raw_pd[\"cloud_fraction\"] = cf_values\n",
    "\n",
    "df_raw_pd[\"date_check\"] = df_raw_pd[\"file_name\"].apply(\n",
    "    lambda fn: date_from_mcd06cosp_filename(fn).date()\n",
    ")\n",
    "df_raw_pd[\"date\"] = df_raw_pd[\"date\"].fillna(df_raw_pd[\"date_check\"])\n",
    "\n",
    "df_curated = (\n",
    "    df_raw_pd[[\"year\", \"date\", \"rel_path\", \"file_name\", \"cloud_fraction\"]]\n",
    "    .drop_duplicates(subset=[\"rel_path\"])\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "curated_output_path = (\n",
    "    f\"{curated_prefix}/calgary_cloud_fraction_summers_2000_2025.parquet\"\n",
    ")\n",
    "df_curated.to_parquet(curated_output_path, index=False, storage_options=storage_options)\n",
    "print(\"Wrote CURATED to:\", curated_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd5dc3b-5f45-44fa-ac67-299f8622a569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>rel_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>cloud_fraction</th>\n",
       "      <th>date_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005-06-01</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005152.062.2022125041308.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005152.062.2022125041308.nc</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>2005-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005-06-02</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005153.062.2022125040416.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005153.062.2022125040416.nc</td>\n",
       "      <td>0.923896</td>\n",
       "      <td>2005-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005-06-03</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005154.062.2022125083517.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005154.062.2022125083517.nc</td>\n",
       "      <td>0.988393</td>\n",
       "      <td>2005-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005-06-04</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005155.062.2022125045129.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005155.062.2022125045129.nc</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>2005-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005-06-05</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005156.062.2022125041611.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2005156.062.2022125041611.nc</td>\n",
       "      <td>0.954493</td>\n",
       "      <td>2005-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc</td>\n",
       "      <td>0.089881</td>\n",
       "      <td>2025-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc</td>\n",
       "      <td>0.366335</td>\n",
       "      <td>2025-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc</td>\n",
       "      <td>0.198984</td>\n",
       "      <td>2025-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-30</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>2025-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc</td>\n",
       "      <td>0.175636</td>\n",
       "      <td>2025-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2173 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year       date                                          rel_path  \\\n",
       "0     2005 2005-06-01  MCD06COSP_D3_MODIS.A2005152.062.2022125041308.nc   \n",
       "1     2005 2005-06-02  MCD06COSP_D3_MODIS.A2005153.062.2022125040416.nc   \n",
       "2     2005 2005-06-03  MCD06COSP_D3_MODIS.A2005154.062.2022125083517.nc   \n",
       "3     2005 2005-06-04  MCD06COSP_D3_MODIS.A2005155.062.2022125045129.nc   \n",
       "4     2005 2005-06-05  MCD06COSP_D3_MODIS.A2005156.062.2022125041611.nc   \n",
       "...    ...        ...                                               ...   \n",
       "2168  2025 2025-08-27  MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc   \n",
       "2169  2025 2025-08-28  MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc   \n",
       "2170  2025 2025-08-29  MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc   \n",
       "2171  2025 2025-08-30  MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc   \n",
       "2172  2025 2025-08-31  MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc   \n",
       "\n",
       "                                             file_name  cloud_fraction  \\\n",
       "0     MCD06COSP_D3_MODIS.A2005152.062.2022125041308.nc        0.999701   \n",
       "1     MCD06COSP_D3_MODIS.A2005153.062.2022125040416.nc        0.923896   \n",
       "2     MCD06COSP_D3_MODIS.A2005154.062.2022125083517.nc        0.988393   \n",
       "3     MCD06COSP_D3_MODIS.A2005155.062.2022125045129.nc        0.936813   \n",
       "4     MCD06COSP_D3_MODIS.A2005156.062.2022125041611.nc        0.954493   \n",
       "...                                                ...             ...   \n",
       "2168  MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc        0.089881   \n",
       "2169  MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc        0.366335   \n",
       "2170  MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc        0.198984   \n",
       "2171  MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc        0.358446   \n",
       "2172  MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc        0.175636   \n",
       "\n",
       "      date_check  \n",
       "0     2005-06-01  \n",
       "1     2005-06-02  \n",
       "2     2005-06-03  \n",
       "3     2005-06-04  \n",
       "4     2005-06-05  \n",
       "...          ...  \n",
       "2168  2025-08-27  \n",
       "2169  2025-08-28  \n",
       "2170  2025-08-29  \n",
       "2171  2025-08-30  \n",
       "2172  2025-08-31  \n",
       "\n",
       "[2173 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0edfe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote classification dataset to: abfs://gold@ucalgarydatalake01.dfs.core.windows.net/calgary_cloud_quality_classification_2000_2025.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>rel_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>cloud_fraction</th>\n",
       "      <th>quality_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002-07-04</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002185.062.2022125093622.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002185.062.2022125093622.nc</td>\n",
       "      <td>0.692232</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002-07-05</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002186.062.2022125090452.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002186.062.2022125090452.nc</td>\n",
       "      <td>0.351298</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002-07-06</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002187.062.2022125093033.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002187.062.2022125093033.nc</td>\n",
       "      <td>0.069563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002-07-07</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002188.062.2022125085450.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002188.062.2022125085450.nc</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002-07-08</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002189.062.2022125093738.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2002189.062.2022125093738.nc</td>\n",
       "      <td>0.999263</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc</td>\n",
       "      <td>0.089881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc</td>\n",
       "      <td>0.366335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc</td>\n",
       "      <td>0.198984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-30</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc</td>\n",
       "      <td>0.358446</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc</td>\n",
       "      <td>MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc</td>\n",
       "      <td>0.175636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2173 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year       date                                          rel_path  \\\n",
       "0     2002 2002-07-04  MCD06COSP_D3_MODIS.A2002185.062.2022125093622.nc   \n",
       "1     2002 2002-07-05  MCD06COSP_D3_MODIS.A2002186.062.2022125090452.nc   \n",
       "2     2002 2002-07-06  MCD06COSP_D3_MODIS.A2002187.062.2022125093033.nc   \n",
       "3     2002 2002-07-07  MCD06COSP_D3_MODIS.A2002188.062.2022125085450.nc   \n",
       "4     2002 2002-07-08  MCD06COSP_D3_MODIS.A2002189.062.2022125093738.nc   \n",
       "...    ...        ...                                               ...   \n",
       "2168  2025 2025-08-27  MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc   \n",
       "2169  2025 2025-08-28  MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc   \n",
       "2170  2025 2025-08-29  MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc   \n",
       "2171  2025 2025-08-30  MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc   \n",
       "2172  2025 2025-08-31  MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc   \n",
       "\n",
       "                                             file_name  cloud_fraction  \\\n",
       "0     MCD06COSP_D3_MODIS.A2002185.062.2022125093622.nc        0.692232   \n",
       "1     MCD06COSP_D3_MODIS.A2002186.062.2022125090452.nc        0.351298   \n",
       "2     MCD06COSP_D3_MODIS.A2002187.062.2022125093033.nc        0.069563   \n",
       "3     MCD06COSP_D3_MODIS.A2002188.062.2022125085450.nc        0.096447   \n",
       "4     MCD06COSP_D3_MODIS.A2002189.062.2022125093738.nc        0.999263   \n",
       "...                                                ...             ...   \n",
       "2168  MCD06COSP_D3_MODIS.A2025239.062.2025247000914.nc        0.089881   \n",
       "2169  MCD06COSP_D3_MODIS.A2025240.062.2025248000944.nc        0.366335   \n",
       "2170  MCD06COSP_D3_MODIS.A2025241.062.2025249001021.nc        0.198984   \n",
       "2171  MCD06COSP_D3_MODIS.A2025242.062.2025250000123.nc        0.358446   \n",
       "2172  MCD06COSP_D3_MODIS.A2025243.062.2025251000147.nc        0.175636   \n",
       "\n",
       "      quality_class  \n",
       "0                 3  \n",
       "1                 2  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 3  \n",
       "...             ...  \n",
       "2168              0  \n",
       "2169              2  \n",
       "2170              1  \n",
       "2171              2  \n",
       "2172              1  \n",
       "\n",
       "[2173 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "GOLD_CONTAINER = \"gold\"\n",
    "gold_prefix = f\"abfs://{GOLD_CONTAINER}@{ACCOUNT_NAME}.dfs.core.windows.net\"\n",
    "\n",
    "curated_path = f\"{curated_prefix}/calgary_cloud_fraction_summers_2000_2025.parquet\"\n",
    "df_curated = pd.read_parquet(curated_path, storage_options=storage_options)\n",
    "df_curated = df_curated.dropna(subset=[\"cloud_fraction\"]).copy()\n",
    "\n",
    "def classify_cf(cf: float) -> int:\n",
    "    if np.isnan(cf):\n",
    "        return -1\n",
    "    if cf < 0.15:\n",
    "        return 0\n",
    "    elif cf < 0.35:\n",
    "        return 1\n",
    "    elif cf < 0.65:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as pool:\n",
    "    classes = list(pool.map(classify_cf, df_curated[\"cloud_fraction\"].tolist()))\n",
    "\n",
    "df_curated[\"quality_class\"] = classes\n",
    "\n",
    "df_class = (\n",
    "    df_curated[[\"year\", \"date\", \"rel_path\", \"file_name\", \"cloud_fraction\", \"quality_class\"]]\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "gold_path = f\"{gold_prefix}/calgary_cloud_quality_classification_2000_2025.parquet\"\n",
    "df_class.to_parquet(gold_path, index=False, storage_options=storage_options)\n",
    "\n",
    "print(\"Wrote classification dataset to:\", gold_path)\n",
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8d30101-1dfa-48ce-9bd0-404952d68dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "gold/calculated_cloud_fraction",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m gold_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabfs://gold@ucalgarydatalake01.dfs.core.windows.net/calculated_cloud_fraction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m gold_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[0;32m      6\u001b[0m     gold_prefix,               \u001b[38;5;66;03m# <-- directory, no glob\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m      8\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# optional but explicit\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(gold_df)\n\u001b[0;32m     14\u001b[0m output_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgold_cloud_fraction.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    268\u001b[0m     path,\n\u001b[0;32m    269\u001b[0m     filesystem,\n\u001b[0;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    277\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    278\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1793\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[0;32m   1787\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1788\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated as of pyarrow 15.0.0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1793\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ParquetDataset(\n\u001b[0;32m   1794\u001b[0m         source,\n\u001b[0;32m   1795\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   1796\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   1797\u001b[0m         partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[0;32m   1798\u001b[0m         memory_map\u001b[38;5;241m=\u001b[39mmemory_map,\n\u001b[0;32m   1799\u001b[0m         read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[0;32m   1800\u001b[0m         buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   1801\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m   1802\u001b[0m         ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes,\n\u001b[0;32m   1803\u001b[0m         pre_buffer\u001b[38;5;241m=\u001b[39mpre_buffer,\n\u001b[0;32m   1804\u001b[0m         coerce_int96_timestamp_unit\u001b[38;5;241m=\u001b[39mcoerce_int96_timestamp_unit,\n\u001b[0;32m   1805\u001b[0m         decryption_properties\u001b[38;5;241m=\u001b[39mdecryption_properties,\n\u001b[0;32m   1806\u001b[0m         thrift_string_size_limit\u001b[38;5;241m=\u001b[39mthrift_string_size_limit,\n\u001b[0;32m   1807\u001b[0m         thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[0;32m   1808\u001b[0m         page_checksum_verification\u001b[38;5;241m=\u001b[39mpage_checksum_verification,\n\u001b[0;32m   1809\u001b[0m     )\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[0;32m   1813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1371\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[1;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partitioning \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhive\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1368\u001b[0m     partitioning \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mHivePartitioning\u001b[38;5;241m.\u001b[39mdiscover(\n\u001b[0;32m   1369\u001b[0m         infer_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mdataset(path_or_paths, filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   1372\u001b[0m                            schema\u001b[38;5;241m=\u001b[39mschema, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[0;32m   1373\u001b[0m                            partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[0;32m   1374\u001b[0m                            ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\dataset.py:794\u001b[0m, in \u001b[0;36mdataset\u001b[1;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[0;32m    783\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    784\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    785\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes\n\u001b[0;32m    791\u001b[0m )\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _filesystem_dataset(source, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\dataset.py:476\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[1;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[0;32m    474\u001b[0m         fs, paths_or_selector \u001b[38;5;241m=\u001b[39m _ensure_multiple_sources(source, filesystem)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m     fs, paths_or_selector \u001b[38;5;241m=\u001b[39m _ensure_single_source(source, filesystem)\n\u001b[0;32m    478\u001b[0m options \u001b[38;5;241m=\u001b[39m FileSystemFactoryOptions(\n\u001b[0;32m    479\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[0;32m    480\u001b[0m     partition_base_dir\u001b[38;5;241m=\u001b[39mpartition_base_dir,\n\u001b[0;32m    481\u001b[0m     exclude_invalid_files\u001b[38;5;241m=\u001b[39mexclude_invalid_files,\n\u001b[0;32m    482\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mselector_ignore_prefixes\n\u001b[0;32m    483\u001b[0m )\n\u001b[0;32m    484\u001b[0m factory \u001b[38;5;241m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\dataset.py:441\u001b[0m, in \u001b[0;36m_ensure_single_source\u001b[1;34m(path, filesystem)\u001b[0m\n\u001b[0;32m    439\u001b[0m     paths_or_selector \u001b[38;5;241m=\u001b[39m [path]\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filesystem, paths_or_selector\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: gold/calculated_cloud_fraction"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gold_prefix = \"abfs://gold@ucalgarydatalake01.dfs.core.windows.net/calculated_cloud_fraction\"\n",
    "\n",
    "gold_df = pd.read_parquet(\n",
    "    gold_prefix,               # <-- directory, no glob\n",
    "    storage_options=storage_options,\n",
    "    engine=\"pyarrow\",          # optional but explicit\n",
    ")\n",
    "\n",
    "\n",
    "print(gold_df)\n",
    "\n",
    "output_csv_path = \"gold_cloud_fraction.csv\"\n",
    "gold_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"CSV written to:\", output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93b2c4-566c-420f-aff6-3c3afb1c2947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
